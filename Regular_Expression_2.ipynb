{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPONSW6NE1Nz9cNLgW/uAqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faisu6339-glitch/Natural-Language-Processing-NLP-/blob/main/Regular_Expression_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DIY PATTERN MATCHINGG"
      ],
      "metadata": {
        "id": "AFe4mqCVfzWK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7add9010"
      },
      "source": [
        "DIY Pattern Matching, in the context of the provided code cells, refers to manually writing code to identify and extract specific patterns from a string, rather than relying on built-in functions or regular expression libraries. In your notebook, you've demonstrated this process by:\n",
        "\n",
        "*   **Iterating through a string:** You loop character by character or by index through the `txt` or `txt1` string.\n",
        "*   **Checking character properties:** You use `isdigit()` to determine if a character is a digit.\n",
        "*   **Maintaining state:** You use a counter (`c`) and sometimes start (`st`) and end (`end`) indices to track consecutive digits.\n",
        "*   **Building patterns:** You append consecutive digits to a `current` string to form a complete number.\n",
        "*   **Storing results:** You collect the extracted numbers into a list (`numbers`) or print them as they are found.\n",
        "\n",
        "Essentially, it's about implementing the logic for pattern recognition yourself, step-by-step, using basic programming constructs like loops, conditional statements, and string manipulation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Continous Numbers"
      ],
      "metadata": {
        "id": "F0OXrnxmdgYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt=\"The number i 852135 not 789646\"\n",
        "\n",
        "for i in range(len(txt)):\n",
        "  print(txt[i],txt[i].isdigit())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OyIjuThcdjn9",
        "outputId": "1d75e964-dffc-47af-83ee-f3ec29b89a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T False\n",
            "h False\n",
            "e False\n",
            "  False\n",
            "n False\n",
            "u False\n",
            "m False\n",
            "b False\n",
            "e False\n",
            "r False\n",
            "  False\n",
            "i False\n",
            "  False\n",
            "8 True\n",
            "5 True\n",
            "2 True\n",
            "1 True\n",
            "3 True\n",
            "5 True\n",
            "  False\n",
            "n False\n",
            "o False\n",
            "t False\n",
            "  False\n",
            "7 True\n",
            "8 True\n",
            "9 True\n",
            "6 True\n",
            "4 True\n",
            "6 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1=\"The number i 852135 not 789646\"\n",
        "\n",
        "c=0\n",
        "for i in range(len(txt1)):\n",
        "  if(txt1[i].isdigit()==True):\n",
        "    print(txt1[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NVx2ftlueUA4",
        "outputId": "c7a8bc47-7d65-4805-ec20-1d8e947b8140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "5\n",
            "2\n",
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "8\n",
            "9\n",
            "6\n",
            "4\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1=\"The number i 852135 not 789646\"\n",
        "\n",
        "for i in range(len(txt1)):\n",
        "  if(txt1[i].isdigit()==True):\n",
        "    c+=1\n",
        "    print(txt1[i],c)\n",
        "  else:\n",
        "    c=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgEdBT3IfQSq",
        "outputId": "b297eac0-e462-41e4-87ce-0fe5a2fdab84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 1\n",
            "5 2\n",
            "2 3\n",
            "1 4\n",
            "3 5\n",
            "5 6\n",
            "7 1\n",
            "8 2\n",
            "9 3\n",
            "6 4\n",
            "4 5\n",
            "6 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1=\"The number i 852135 not 789646\"\n",
        "\n",
        "for i in range(len(txt1)):\n",
        "  if(txt1[i].isdigit()==True):\n",
        "    c+=1\n",
        "    print(txt1[i],c,i)\n",
        "  else:\n",
        "    c=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF9BR2tHfQ-Q",
        "outputId": "c467ed01-4ae1-4289-9d4f-5ecca0619311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 1 13\n",
            "5 2 14\n",
            "2 3 15\n",
            "1 4 16\n",
            "3 5 17\n",
            "5 6 18\n",
            "7 1 24\n",
            "8 2 25\n",
            "9 3 26\n",
            "6 4 27\n",
            "4 5 28\n",
            "6 6 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1 = \"The number is 852135 not 789646\"\n",
        "\n",
        "c = 0\n",
        "index = []\n",
        "\n",
        "for i in range(len(txt1)):\n",
        "    if txt1[i].isdigit():\n",
        "        if c == 0:\n",
        "            print(\"START\")\n",
        "        c += 1\n",
        "        index.append(i)   # store index of digit\n",
        "        print(txt1[i], c)\n",
        "    else:\n",
        "        if c != 0:\n",
        "            print(\"END at index\", i)\n",
        "        c = 0\n",
        "\n",
        "print(\"Digit indices:\", index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMc2fHDTfomZ",
        "outputId": "4f0ee0c2-6f2b-42b0-e23a-9be6fac8dda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START\n",
            "8 1\n",
            "5 2\n",
            "2 3\n",
            "1 4\n",
            "3 5\n",
            "5 6\n",
            "END at index 20\n",
            "START\n",
            "7 1\n",
            "8 2\n",
            "9 3\n",
            "6 4\n",
            "4 5\n",
            "6 6\n",
            "Digit indices: [14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1 = \"The number is 852135 not 789646\"\n",
        "\n",
        "numbers = []\n",
        "current = \"\"\n",
        "\n",
        "for ch in txt1:\n",
        "    if ch.isdigit():\n",
        "        current += ch\n",
        "    else:\n",
        "        if current:\n",
        "            numbers.append(current)\n",
        "            current = \"\"\n",
        "\n",
        "if current:\n",
        "    numbers.append(current)\n",
        "\n",
        "print(numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWYKMQAYg1Ke",
        "outputId": "d8f101f6-42c7-458e-93c6-60adc8fe18b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['852135', '789646']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = 'The number is 8372493 not 423423'\n",
        "c = 0\n",
        "\n",
        "for i in range(len(txt)):\n",
        "    if txt[i].isdigit():\n",
        "        if c == 0:\n",
        "            st = i\n",
        "        c += 1\n",
        "    else:\n",
        "        if c != 0:\n",
        "            end = i\n",
        "            print(txt[st:end])\n",
        "            c = 0\n",
        "\n",
        "if c != 0:\n",
        "    print(txt[-c:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzKsBOpdhPuV",
        "outputId": "2de4ae22-91c7-4c52-a337-cd06c4b167cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8372493\n",
            "423423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pattern Matching"
      ],
      "metadata": {
        "id": "2957FYDoiSSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am learning NLP\"\n",
        "pattern = \"NLP\"\n",
        "\n",
        "for i in range(len(text) - len(pattern) + 1):\n",
        "    match = True\n",
        "    for j in range(len(pattern)):\n",
        "        if text[i + j] != pattern[j]:\n",
        "            match = False\n",
        "            break\n",
        "    if match:\n",
        "        print(\"Pattern found at index\", i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyS9jPkYhoHh",
        "outputId": "778b9f7a-7b32-4209-c62c-140cdcb3f21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pattern found at index 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am Learning NLP\"\n",
        "pattern = \"nlp\"\n",
        "\n",
        "text = text.lower()\n",
        "pattern = pattern.lower()\n",
        "\n",
        "for i in range(len(text) - len(pattern) + 1):\n",
        "    if text[i:i+len(pattern)] == pattern:\n",
        "        print(\"Found at index\", i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llbtLEObiGc2",
        "outputId": "49fd20b9-ea8f-4024-94cd-ad993dfe1fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found at index 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NLP is fun. NLP is powerful. NLP is future\"\n",
        "pattern = \"NLP\"\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in range(len(text) - len(pattern) + 1):\n",
        "    if text[i:i+len(pattern)] == pattern:\n",
        "        count += 1\n",
        "\n",
        "print(\"Total occurrences:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZbnjHVtiL7i",
        "outputId": "079e1891-de9a-4fb0-d080-adedfe8fb137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total occurrences: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"cat category cat dog\"\n",
        "pattern = \"cat\"\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    if word == pattern:\n",
        "        print(\"Found at word position\", i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjPco-BgiV41",
        "outputId": "44bb23ea-0575-47d3-a1e6-e92aa799681f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found at word position 0\n",
            "Found at word position 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"banana\"\n",
        "pattern = \"ana\"\n",
        "\n",
        "indexes = []\n",
        "\n",
        "for i in range(len(text) - len(pattern) + 1):\n",
        "    if text[i:i+len(pattern)] == pattern:\n",
        "        indexes.append(i)\n",
        "\n",
        "print(indexes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2EN_rdmibuD",
        "outputId": "9e48c5fc-0907-41d5-9e6e-bac78b4a157d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPbt7n-rilKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d2c75d4"
      },
      "source": [
        "# Task\n",
        "Explain and demonstrate different methods for word finding in text. This includes a simple substring search, tokenizing text for exact word matching, case-insensitive word finding, and finding all occurrences of a word along with their starting indices. Finally, summarize the techniques and their suitable use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5e83191"
      },
      "source": [
        "## Explain Word Finding\n",
        "\n",
        "### Subtask:\n",
        "Provide a detailed explanation of 'word finding', including its definition, common challenges, and different strategies used in programming.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4598808d"
      },
      "source": [
        "### What is Word Finding?\n",
        "\n",
        "In the context of text analysis and programming, 'word finding' refers to the process of identifying and extracting specific words or patterns within a larger body of text (a string). This often involves searching for exact matches, partial matches, or sequences of characters that conform to a predefined pattern.\n",
        "\n",
        "### Common Challenges in Word Finding:\n",
        "\n",
        "1.  **Case Sensitivity:** A common issue where 'Word' is treated differently from 'word'. Ensuring matches regardless of case requires specific handling.\n",
        "2.  **Punctuation:** Punctuation marks attached to words (e.g., 'word.', 'word,', '(word)') can prevent an exact match, requiring pre-processing or more complex pattern recognition.\n",
        "3.  **Partial Matches:** Sometimes, we need to find occurrences where a pattern is part of a larger word (e.g., finding 'cat' in 'category').\n",
        "4.  **Whitespace and Delimiters:** Different types of whitespace (spaces, tabs, newlines) or other delimiters can affect how words are recognized.\n",
        "5.  **Efficiency:** For very large texts, the speed of the word-finding algorithm becomes crucial.\n",
        "6.  **Overlapping Matches:** When searching for patterns, determining if overlapping occurrences should be counted or if only distinct matches are desired.\n",
        "\n",
        "### Strategies for Word Finding (to be demonstrated):\n",
        "\n",
        "1.  **Simple Substring Search:** Directly checking if a smaller string (pattern) exists within a larger string using basic string methods or loops.\n",
        "2.  **Tokenization:** Breaking down the text into individual words (tokens) first, often using whitespace or punctuation as delimiters, then searching within this list of tokens.\n",
        "3.  **Case-Insensitive Matching:** Converting both the text and the pattern to a common case (e.g., lowercase) before performing the search.\n",
        "4.  **Finding All Occurrences:** Identifying every instance where a word or pattern appears in the text, rather than just the first one.\n",
        "5.  **Regular Expressions:** A powerful tool for defining complex search patterns, including wildcard characters, character sets, and repetition quantifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166a6229"
      },
      "source": [
        "## Program Type 1: Simple Substring Search\n",
        "\n",
        "### Subtask:\n",
        "Demonstrate finding a word using a basic substring search method, similar to how 'NLP' was found in cell `llbtLEObiGc2`. This will focus on finding a sequence of characters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "497886ab"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a new code cell to demonstrate the simple substring search as instructed, using a `for` loop and string slicing to find the pattern.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fa036b9",
        "outputId": "8b0e8a65-58db-44db-f7db-e86182d6ba0c"
      },
      "source": [
        "text = \"Python programming is fun\"\n",
        "pattern = \"prog\"\n",
        "\n",
        "print(f\"Searching for '{pattern}' in '{text}'\")\n",
        "\n",
        "for i in range(len(text) - len(pattern) + 1):\n",
        "    if text[i:i+len(pattern)] == pattern:\n",
        "        print(\"Pattern found at index\", i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for 'prog' in 'Python programming is fun'\n",
            "Pattern found at index 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99b0a752"
      },
      "source": [
        "This method performs a **simple substring search**, meaning it looks for a contiguous sequence of characters (`pattern`) anywhere within the `text` string. It directly compares slices of the text to the pattern.\n",
        "\n",
        "**Characteristics:**\n",
        "*   **Simplicity:** It's straightforward to implement using basic string slicing and loops.\n",
        "*   **Contiguous Match:** It finds exact matches of the character sequence as it appears.\n",
        "\n",
        "**Limitations:**\n",
        "*   **Not Word-Aware:** It doesn't distinguish between whole words and parts of words. For example, searching for \"cat\" would match in \"category\" or \"concatenate\", not just the standalone word \"cat\".\n",
        "*   **Case Sensitive (by default):** Without explicit conversion, \"NLP\" will not match \"nlp\" (as demonstrated in previous cells).\n",
        "*   **Punctuation:** It treats punctuation as part of the string, so \"word.\" would not match \"word\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3d2a7de"
      },
      "source": [
        "## Program Type 2: Tokenization for Exact Word Matching\n",
        "\n",
        "### Subtask:\n",
        "Demonstrate finding an exact word match using tokenization to handle punctuation and case insensitivity. The goal is to find only whole words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ebce50c"
      },
      "source": [
        "This block introduces the next program type, 'Tokenization for Exact Word Matching', and outlines the subtask for this section, which is to demonstrate finding exact word matches using tokenization, while also handling punctuation and case insensitivity. The explicit goal is to focus on whole words only, distinguishing it from the previous substring search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b48455a6",
        "outputId": "f840b0f3-96c1-44e4-feff-f73fa8f9a442"
      },
      "source": [
        "import string\n",
        "\n",
        "text = \"NLP is fun! nlp is powerful, and nLp is future.\"\n",
        "pattern = \"nlp\"\n",
        "\n",
        "print(f\"Searching for '{pattern}' (case-insensitive, whole word) in '{text}'\\n\")\n",
        "\n",
        "alphabetic_text = ''.join(char.lower() if char.isalpha() or char.isspace() else ' ' for char in text)\n",
        "words = [word for word in alphabetic_text.split() if word]\n",
        "\n",
        "found_indices = []\n",
        "for i, word in enumerate(words):\n",
        "    if word == pattern.lower():\n",
        "        found_indices.append(i)\n",
        "\n",
        "if found_indices:\n",
        "    print(f\"Pattern '{pattern}' found as a whole word at word positions: {found_indices}\")\n",
        "else:\n",
        "    print(f\"Pattern '{pattern}' not found as a whole word.\")\n",
        "\n",
        "# For exact index in original text (more complex, but often needed):\n",
        "# Re-tokenize with original words and map positions\n",
        "original_words_with_punct = text.lower().split()\n",
        "clean_words_to_original_mapping = []\n",
        "start_index = 0\n",
        "for original_word_punct in original_words_with_punct:\n",
        "    clean_word = original_word_punct.strip(string.punctuation)\n",
        "    if clean_word:\n",
        "        clean_words_to_original_mapping.append((clean_word, start_index))\n",
        "    start_index += len(original_word_punct) + 1 # +1 for space\n",
        "\n",
        "print(\"\\nOriginal word positions with punctuation stripped:\")\n",
        "for clean_word, original_idx in clean_words_to_original_mapping:\n",
        "    if clean_word == pattern.lower():\n",
        "        print(f\"Found '{clean_word}' at approximate original index {original_idx}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for 'nlp' (case-insensitive, whole word) in 'NLP is fun! nlp is powerful, and nLp is future.'\n",
            "\n",
            "Pattern 'nlp' found as a whole word at word positions: [0, 3, 7]\n",
            "\n",
            "Original word positions with punctuation stripped:\n",
            "Found 'nlp' at approximate original index 0\n",
            "Found 'nlp' at approximate original index 12\n",
            "Found 'nlp' at approximate original index 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lx7UuW4BjWIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd39cb9"
      },
      "source": [
        "This method uses **tokenization** to perform **exact word matching**, offering a more robust search compared to simple substring search. It addresses common challenges like case sensitivity and punctuation by pre-processing the text.\n",
        "\n",
        "**Key Steps:**\n",
        "1.  **Normalization (Case Conversion):** Both the text and the pattern are converted to a consistent case (e.g., lowercase) to ensure case-insensitive matching.\n",
        "2.  **Punctuation Handling:** Punctuation marks are either removed or replaced with spaces to ensure they don't interfere with word boundaries. This allows 'fun!' to be recognized as 'fun'.\n",
        "3.  **Tokenization:** The cleaned text is split into individual words (tokens), typically using whitespace as a delimiter.\n",
        "4.  **Exact Match Comparison:** Each token is then directly compared to the normalized pattern.\n",
        "\n",
        "**Characteristics:**\n",
        "*   **Word-Aware:** It finds only whole words, not partial matches within other words (e.g., searching for \"cat\" will not match in \"category\").\n",
        "*   **Case-Insensitive:** Effectively handles variations in capitalization.\n",
        "*   **Punctuation-Robust:** Ignores punctuation attached to words, finding the core word.\n",
        "*   **Provides Word Positions:** Can easily identify the position of the word within the sequence of tokens.\n",
        "\n",
        "**Limitations:**\n",
        "*   **More Complex Pre-processing:** Requires additional steps for cleaning and tokenizing the text.\n",
        "*   **Loss of Original Index (without extra mapping):** Directly returning token indices doesn't give the precise character index in the original text without further logic to map back.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4733c5ec"
      },
      "source": [
        "## Program Type 3: Case-Insensitive Word Finding\n",
        "\n",
        "### Subtask:\n",
        "Illustrate how to perform word finding that ignores case differences by converting both the text and the pattern to a consistent case before comparison.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18701440"
      },
      "source": [
        "A practical demonstration of **case-insensitive word finding** can be observed in cell `llbtLEObiGc2`. In that example, both the `text` and `pattern` were explicitly converted to lowercase using `.lower()` before the substring search was performed. This ensures that matches occur regardless of the original casing in the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c91be89"
      },
      "source": [
        "### Characteristics and Limitations of Case-Insensitive Substring Search\n",
        "\n",
        "This method primarily addresses the challenge of **case sensitivity** by standardizing the case (e.g., lowercase) of both the text and the pattern before comparison. This means that 'NLP', 'nlp', and 'Nlp' will all be treated as the same when searching for 'nlp'.\n",
        "\n",
        "**Characteristics:**\n",
        "*   **Case-Insensitive:** Successfully finds patterns regardless of their casing in the original text.\n",
        "*   **Simplicity:** Remains relatively simple to implement, building upon the basic substring search.\n",
        "\n",
        "**Limitations:**\n",
        "*   **Still Not Word-Aware:** Like the simple substring search, it still treats the pattern as a sequence of characters rather than a whole word. For instance, searching for 'cat' (case-insensitive) would still match 'category' or 'concatenate'.\n",
        "*   **Punctuation Handling:** It does not inherently handle punctuation. If the pattern is 'word' and the text contains 'word!', it would not match directly unless the punctuation is removed or ignored during comparison. To truly ignore punctuation, more advanced text processing (like tokenization and stripping punctuation) is required, as demonstrated in the 'Tokenization for Exact Word Matching' section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82eb0eb9"
      },
      "source": [
        "## Program Type 4: Finding All Occurrences and Indices\n",
        "\n",
        "### Subtask:\n",
        "Develop a program to find and list all occurrences of a specific word, along with their starting indices within the original text. This expands on the previous examples to capture all instances.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "231ca8ec"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a new code cell to demonstrate finding all occurrences of a specific word and their starting indices, following the provided instructions for simple substring search.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35950b15",
        "outputId": "c8838b2e-c400-488c-e8ce-4f3548479438"
      },
      "source": [
        "text = \"The cat sat on the mat, and another cat appeared.\"\n",
        "pattern = \"cat\"\n",
        "\n",
        "found_indices = []\n",
        "\n",
        "for i in range(len(text) - len(pattern) + 1):\n",
        "    if text[i:i+len(pattern)] == pattern:\n",
        "        found_indices.append(i)\n",
        "\n",
        "print(f\"Searching for '{pattern}' in '{text}'\")\n",
        "print(f\"Pattern '{pattern}' found at indices: {found_indices}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for 'cat' in 'The cat sat on the mat, and another cat appeared.'\n",
            "Pattern 'cat' found at indices: [4, 36]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f38b0b0e"
      },
      "source": [
        "This method focuses on finding **all occurrences** of a pattern within a text and providing their **starting indices**. It uses a direct substring comparison approach, iterating through the text and checking for matches.\n",
        "\n",
        "**Characteristics:**\n",
        "*   **Comprehensive:** Identifies every instance where the pattern appears as a contiguous sequence of characters.\n",
        "*   **Index-Specific:** Provides the exact starting character index for each match in the original text.\n",
        "*   **Simplicity:** Builds directly on the basic substring search logic.\n",
        "\n",
        "**Limitations:**\n",
        "*   **Case Sensitive (by default):** Unless explicitly handled (e.g., converting both text and pattern to lowercase), it will not match patterns with different casing (e.g., 'Cat' will not match 'cat').\n",
        "*   **Not Word-Aware:** Similar to the simple substring search, it will match the pattern even if it's part of a larger word (e.g., 'cat' would match in 'category').\n",
        "*   **Punctuation Sensitivity:** Punctuation attached to words will prevent a match unless removed or accounted for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2ea0bd"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the different 'word finding' techniques demonstrated and explain when each approach might be most suitable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cba957b1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "The different 'word finding' techniques demonstrated, and when each approach might be most suitable, are summarized below:\n",
        "\n",
        "*   **Simple Substring Search**:\n",
        "    *   **Technique**: Directly checks if a smaller string exists within a larger string by comparing character sequences.\n",
        "    *   **Suitability**: Best for finding exact character sequences, even if they are parts of larger words, or when strict case and punctuation matching is required. It's the simplest to implement for basic presence checks.\n",
        "\n",
        "*   **Tokenization for Exact Word Matching (Case-Insensitive, Punctuation-Robust)**:\n",
        "    *   **Technique**: Involves pre-processing text by normalizing case, handling punctuation, and then splitting the text into individual words (tokens) before comparing each token to the pattern.\n",
        "    *   **Suitability**: Ideal for scenarios where you need to find whole words, ignoring case differences and punctuation attached to words. This is suitable for general text analysis where semantic word matching is more important than literal character sequence matching.\n",
        "\n",
        "*   **Case-Insensitive Word Finding (via Substring Search with `.lower()`)**:\n",
        "    *   **Technique**: Converts both the text and the pattern to a consistent case (e.g., lowercase) before performing a simple substring search.\n",
        "    *   **Suitability**: Useful when you need to find a character sequence regardless of its capitalization, but you are not concerned with whole-word boundaries or attached punctuation. It's a quick modification to a simple substring search.\n",
        "\n",
        "*   **Finding All Occurrences and Indices (via Substring Search)**:\n",
        "    *   **Technique**: Iterates through the text to find every instance of a pattern and records the starting character index for each match.\n",
        "    *   **Suitability**: Applicable when you need to locate all positions of a specific character sequence within the text, not just the first one. Similar to simple substring search, it's case and punctuation-sensitive by default and not word-aware unless combined with other techniques.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Definition of Word Finding**: It is the process of identifying and extracting specific words or patterns from a larger body of text.\n",
        "*   **Common Challenges**: Case sensitivity, punctuation, partial matches, whitespace/delimiters, efficiency, and overlapping matches are key challenges.\n",
        "*   **Simple Substring Search Demonstration**:\n",
        "    *   Found the pattern \"prog\" in \"Python programming is fun\" at index 7.\n",
        "    *   **Characteristics**: Simple, finds contiguous character sequences.\n",
        "    *   **Limitations**: Not word-aware, case-sensitive by default, and doesn't handle punctuation gracefully.\n",
        "*   **Tokenization for Exact Word Matching Demonstration**:\n",
        "    *   Found the pattern \"nlp\" (case-insensitive, whole word) in \"NLP is fun! nlp is powerful, and nLp is future.\" at word positions [0, 3, 7].\n",
        "    *   Approximate original character indices found were 0, 12, and 33.\n",
        "    *   **Characteristics**: Word-aware, case-insensitive, punctuation-robust, provides word positions.\n",
        "    *   **Limitations**: Requires more complex pre-processing and mapping back to original character indices can be complex.\n",
        "*   **Case-Insensitive Word Finding (Substring) Explanation**:\n",
        "    *   Achieved by converting both text and pattern to a common case (e.g., `.lower()`) before comparison.\n",
        "    *   **Characteristics**: Successfully finds patterns regardless of casing, simple to implement.\n",
        "    *   **Limitations**: Still not word-aware (e.g., \"cat\" matches \"category\"), does not inherently handle punctuation.\n",
        "*   **Finding All Occurrences and Indices (Substring) Demonstration**:\n",
        "    *   Found the pattern \"cat\" in \"The cat sat on the mat, and another cat appeared.\" at indices [4, 36].\n",
        "    *   **Characteristics**: Comprehensive (identifies every instance), index-specific, simple.\n",
        "    *   **Limitations**: Case-sensitive by default, not word-aware, and punctuation-sensitive.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The choice of word-finding technique depends heavily on the specific requirements: for simple pattern presence, substring search suffices; for semantic word understanding, tokenization and normalization are crucial.\n",
        "*   Future analysis could explore advanced word-finding methods using regular expressions to combine flexibility in pattern matching with capabilities for case-insensitivity, whole-word matching, and punctuation handling in a single, powerful tool.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YecQ70Y1ju-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1️⃣ Simple Word Finding (Using Loop)"
      ],
      "metadata": {
        "id": "LmYzQGiGjuSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am learning NLP\"\n",
        "word = \"learning\"\n",
        "\n",
        "found = False\n",
        "\n",
        "for i in range(len(text) - len(word) + 1):\n",
        "    if text[i:i+len(word)] == word:\n",
        "        print(\"Word found at index\", i)\n",
        "        found = True\n",
        "\n",
        "if not found:\n",
        "    print(\"Word not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qew1WaqgjxHM",
        "outputId": "02a14400-3ee3-448b-c8c7-30e6cd1af2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word found at index 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2️⃣ Case-Insensitive Word Finding ⭐"
      ],
      "metadata": {
        "id": "0Lpwk_Vgj0jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I Am Learning NLP\"\n",
        "word = \"learning\"\n",
        "\n",
        "text = text.lower()\n",
        "word = word.lower()\n",
        "\n",
        "for i in range(len(text) - len(word) + 1):\n",
        "    if text[i:i+len(word)] == word:\n",
        "        print(\"Word found at index\", i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2A40jVbjyVa",
        "outputId": "b637347c-ca22-4b0c-8ca2-674ed110dcd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word found at index 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3️⃣ Count How Many Times a Word Appears"
      ],
      "metadata": {
        "id": "_UFS__O1j7GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"NLP is fun and NLP is powerful\"\n",
        "word=\"NLP\"\n",
        "\n",
        "count=0\n",
        "\n",
        "for i in range(len(text)-len(word)+1):\n",
        "  if text[i:i+len(word)]==word:\n",
        "    count+=1\n",
        "    print(\"Word found at index\",i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG-JMQmtj4kE",
        "outputId": "71af55df-e6a8-4ede-94f1-358f11f1921e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word found at index 0\n",
            "Word found at index 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4️⃣ Find All Index Positions of a Word"
      ],
      "metadata": {
        "id": "6_vUoEcRkfls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"banana\"\n",
        "word = \"ana\"\n",
        "\n",
        "positions = []\n",
        "\n",
        "for i in range(len(text) - len(word) + 1):\n",
        "    if text[i:i+len(word)] == word:\n",
        "        positions.append(i)\n",
        "\n",
        "print(positions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OorTMVRzkWKf",
        "outputId": "a34d519c-e029-4328-f0e9-3ea583d4e5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSBv15QGklx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regex Word Finding"
      ],
      "metadata": {
        "id": "BO3uw7RstHa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text=\"I am Learning NLP\"\n",
        "word=\"Learning\"\n",
        "\n",
        "match=re.search(word,text)\n",
        "\n",
        "if match:\n",
        "  print(\"Word found at index\",match.start())\n",
        "else:\n",
        "  print(\"Word not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywKCK5nftHwF",
        "outputId": "2b65b003-9b21-4d18-a944-1fa62c448ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word found at index 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case-Insensitive Word Finding"
      ],
      "metadata": {
        "id": "hkgSJQRUtdaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"I Am Learning NLP\"\n",
        "word = \"learning\"\n",
        "\n",
        "match = re.search(word, text, re.IGNORECASE)\n",
        "\n",
        "if match:\n",
        "    print(\"Word found at index\", match.start())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxLGYZMGtY2f",
        "outputId": "e9edb824-9532-4fc8-a89d-719bb95ca2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word found at index 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"NLP is fun. NLP is powerful. NLP is future\"\n",
        "word = \"NLP\"\n",
        "\n",
        "matches = re.finditer(word, text)\n",
        "\n",
        "for m in matches:\n",
        "    print(\"Found at index\", m.start())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9l8kyyYtgHy",
        "outputId": "b1c2075d-8c88-46ed-f5d8-b81a932a281a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found at index 0\n",
            "Found at index 12\n",
            "Found at index 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"Let us study Data Science from GFG.\"\n",
        "txt = txt.lower()\n",
        "word = 'data'            # Word to search\n",
        "\n",
        "for i in range(len(txt)):\n",
        "    if txt[i:i+len(word)] == word:\n",
        "        print(i, i+len(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJRMv5FFtjo9",
        "outputId": "728f0bc8-a825-4359-f744-43f473464ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"AI will change AI and AI will grow\"\n",
        "word = r\"\\bAI\\b\"\n",
        "\n",
        "count = len(re.findall(word, text))\n",
        "print(\"Total count:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1NPPmLLt7E0",
        "outputId": "54da4303-6940-497d-b83b-ad585ac1f7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total count: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = 'AI is having the capability to revolutionize all the industries. The Industry is ready for a big change'\n",
        "word = 'in'\n",
        "\n",
        "for wrd in txt.split(' '):\n",
        "    if (wrd[:2].lower() == word.lower()):\n",
        "        print(wrd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N7gYtOPtny-",
        "outputId": "63b5921a-1f2a-428b-a91b-e04b3d9a2ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "industries.\n",
            "Industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing Needs New Networks\"\n",
        "start_char = 'N'\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "for word in words:\n",
        "    if word.startswith(start_char):\n",
        "        print(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CuLIi5Itsm5",
        "outputId": "2d139a6a-4e11-424c-bde7-fddef6bbbefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\n",
            "Needs\n",
            "New\n",
            "Networks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing needs New networks\"\n",
        "start_char = 'n'\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "for word in words:\n",
        "    if word.lower().startswith(start_char.lower()):\n",
        "        print(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPwT3r2WuBBQ",
        "outputId": "01241390-b185-42f8-9492-972bd1c00f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\n",
            "needs\n",
            "New\n",
            "networks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Machine learning models make meaningful metrics\"\n",
        "start_char = 'm'\n",
        "\n",
        "result = []\n",
        "\n",
        "for word in text.split():\n",
        "    if word.lower().startswith(start_char.lower()):\n",
        "        result.append(word)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PeXAtO9uFIJ",
        "outputId": "78b02f0e-c553-4ba8-923a-0b9ad39262f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine', 'models', 'make', 'meaningful', 'metrics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Punctuation"
      ],
      "metadata": {
        "id": "S-Ao8AY9uNw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Data, driven. decisions! define digital-development\"\n",
        "start_char = 'd'\n",
        "\n",
        "clean_word = \"\"\n",
        "result = []\n",
        "\n",
        "for ch in text:\n",
        "    if ch.isalpha():\n",
        "        clean_word += ch\n",
        "    else:\n",
        "        if clean_word:\n",
        "            if clean_word.lower().startswith(start_char.lower()):\n",
        "                result.append(clean_word)\n",
        "            clean_word = \"\"\n",
        "\n",
        "if clean_word:\n",
        "    if clean_word.lower().startswith(start_char.lower()):\n",
        "        result.append(clean_word)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJKcq0uhuHsv",
        "outputId": "3dfa6eeb-5ec2-4f0c-9f27-b16e0573bc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data', 'driven', 'decisions', 'define', 'digital', 'development']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = 'AI is having the capability to revolutionize all the industries. The Industry is ready for a big change'\n",
        "word = 'he'\n",
        "\n",
        "for wrd in txt.split(' '):\n",
        "    if(wrd[-2:].lower() == word.lower()):\n",
        "        print(wrd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yXb3JHnuQW6",
        "outputId": "d39edecb-2d6e-45cf-f7af-6003e59c1451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "the\n",
            "The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Word Pairs\n"
      ],
      "metadata": {
        "id": "db695geguaKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt = 'AI is having the capability to revolutionize all the industries. The Industry is ready for a big change'\n",
        "\n",
        "for i in range(len(txt.split(' '))-1):\n",
        "    print(txt.split(' ')[i], txt.split(' ')[i + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HW3R3tmPuUal",
        "outputId": "0281dc7b-0235-41e0-8373-0016d62498cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI is\n",
            "is having\n",
            "having the\n",
            "the capability\n",
            "capability to\n",
            "to revolutionize\n",
            "revolutionize all\n",
            "all the\n",
            "the industries.\n",
            "industries. The\n",
            "The Industry\n",
            "Industry is\n",
            "is ready\n",
            "ready for\n",
            "for a\n",
            "a big\n",
            "big change\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Email Parsing"
      ],
      "metadata": {
        "id": "8aDvKImDulBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mails = [\n",
        "    'eshant@gmail.com',\n",
        "    'eshant@gfg.org',\n",
        "    'eshant@yahoo.com',\n",
        "    'eshant@aap.gov.in',\n",
        "    'esh@geeksforgeeks.com',\n",
        "    'esh@mail.com',\n",
        "    'eshant@orkut.com'\n",
        "]\n",
        "\n",
        "user_id = []\n",
        "host_name = []\n",
        "domain_type = []\n",
        "\n",
        "for mail in mails:\n",
        "    user_id.append(mail.split('@')[0])\n",
        "    host_name.append(mail.split('@')[1].split('.')[0])\n",
        "    domain_type.append('.'.join(mail.split('@')[1].split('.')[1:]))\n",
        "\n",
        "print(user_id)\n",
        "print(host_name)\n",
        "print(domain_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tRL7TVjuda-",
        "outputId": "e4825d75-166c-42d0-f793-5a0c67da2ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eshant', 'eshant', 'eshant', 'eshant', 'esh', 'esh', 'eshant']\n",
            "['gmail', 'gfg', 'yahoo', 'aap', 'geeksforgeeks', 'mail', 'orkut']\n",
            "['com', 'org', 'com', 'gov.in', 'com', 'com', 'com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQZTKSbHundw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}